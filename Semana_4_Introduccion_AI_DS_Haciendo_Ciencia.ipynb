{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Semana 4: Implementación de Modelos de Deep learning\n",
        "\n",
        "Autor: Dan Santivañez Gutarra\n",
        "\n",
        "\n",
        "### Objetivos:\n",
        "*   Explorar el uso de una Red Neuronal Artificial (ANN)\n",
        "*   Explorar el uso de una Red Neuronal Convolucional (CNN)\n",
        "*   Explorar el uso de una Red Neuronal Recurrente (RNN)\n"
      ],
      "metadata": {
        "id": "X9XkjC7nccq3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Configuración del Entorno\n",
        "Instalamos e importamos las librerías necesarias para trabajar con los datos y modelos.\n"
      ],
      "metadata": {
        "id": "T2FXmTR6fN8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub\n",
        "import kagglehub\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_squared_error, mean_absolute_error, precision_score, recall_score\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fCsfUH-XZKXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Red Neuronal Artificial (ANN) - Heart Disease"
      ],
      "metadata": {
        "id": "hRi8_KBaFacO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Red Neuronal Artificial (ANN):**  \n",
        "Es un modelo básico con capas densamente conectadas, ideal para clasificación y regresión con datos tabulares, como predecir enfermedades cardíacas.\n"
      ],
      "metadata": {
        "id": "7iazFvHEFdOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Cargar y explorar el dataset"
      ],
      "metadata": {
        "id": "XgLHjwhGFjPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"redwankarimsony/heart-disease-data\")\n",
        "heart_disease_path = os.path.join(path, 'heart_disease_uci.csv')\n",
        "df_heart = pd.read_csv(heart_disease_path)\n",
        "print(\"Primeras filas del dataset:\")\n",
        "df_heart.head()"
      ],
      "metadata": {
        "id": "YL80LOzsFbMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Preprocesamiento"
      ],
      "metadata": {
        "id": "0-R8fyAaFwN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - Eliminamos valores nulos.\n",
        "df_heart = df_heart.dropna()\n",
        "le = LabelEncoder()\n",
        "for column in ['sex', 'dataset', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']:\n",
        "    df_heart[column] = le.fit_transform(df_heart[column])"
      ],
      "metadata": {
        "id": "zLSxtSO3Fh8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# - Codificamos variables categóricas.\n",
        "X = df_heart.drop(['id', 'num'], axis=1)\n",
        "y = df_heart['num'].apply(lambda x: 1 if x > 0 else 0)"
      ],
      "metadata": {
        "id": "AHFHiTjUF23e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# - Escalamos características numéricas.\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gQQo6P9IF5q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Construcción del modelo ANN"
      ],
      "metadata": {
        "id": "ZQxWGZgaGo_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ann = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model_ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_ann.summary()"
      ],
      "metadata": {
        "id": "IZz6KbFxGv46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_ann = model_ann.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "id": "Pwg0tQYVG0O2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5 Evaluación y Visualización"
      ],
      "metadata": {
        "id": "4CINtdoxG8Zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluación\n",
        "y_pred = (model_ann.predict(X_test) > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "6QDi2z3LHIZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "cEeQ0X41HLFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de Confusión\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Matriz de Confusión - ANN')\n",
        "plt.xlabel('Predicho')\n",
        "plt.ylabel('Real')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7cxcWhekHNyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pérdida y Precisión\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history_ann.history['loss'], label='Pérdida Entrenamiento')\n",
        "plt.plot(history_ann.history['val_loss'], label='Pérdida Validación')\n",
        "plt.title('Pérdida - ANN')\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history_ann.history['accuracy'], label='Precisión Entrenamiento')\n",
        "plt.plot(history_ann.history['val_accuracy'], label='Precisión Validación')\n",
        "plt.title('Precisión - ANN')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GDfDri_THRql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribución de Clases\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x=y)\n",
        "plt.title('Distribución de Enfermedad Cardíaca')\n",
        "plt.xlabel('Enfermedad (0: No, 1: Sí)')\n",
        "plt.ylabel('Cantidad')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "to0Qr6ADHWYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Curva Precision-Recall\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "prec, rec, _ = precision_recall_curve(y_test, model_ann.predict(X_test))\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(rec, prec, marker='.')\n",
        "plt.title('Curva Precision-Recall - ANN')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6JW8Im4YHY03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplos de Predicciones para ANN\n",
        "# Seleccionamos 10 ejemplos aleatorios del conjunto de prueba\n",
        "indices = np.random.choice(len(X_test), 10, replace=False)\n",
        "X_sample = X_test[indices]\n",
        "y_sample_real = y_test.iloc[indices] if isinstance(y_test, pd.Series) else y_test[indices]\n",
        "y_sample_pred = (model_ann.predict(X_sample) > 0.5).astype(int).flatten()\n",
        "\n",
        "# Mostramos las predicciones y las etiquetas reales\n",
        "for i in range(10):\n",
        "    print(f\"Ejemplo {i+1}:\")\n",
        "    print(f\"Características (escaladas): {X_sample[i][:5]}...\")  # Mostramos las primeras 5 características\n",
        "    print(f\"Predicción: {y_sample_pred[i]}, Real: {y_sample_real[i]}\")\n",
        "    print(f\"Correcto: {'Sí' if y_sample_pred[i] == y_sample_real[i] else 'No'}\")\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "oZN65AJfMxwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Función objetivo\n",
        "def f(x):\n",
        "    return x**2\n",
        "\n",
        "# Derivada de la función objetivo\n",
        "def df(x):\n",
        "    return 2*x\n",
        "\n",
        "# Parámetros del gradiente descendiente\n",
        "learning_rate = 0.1\n",
        "iterations = 20\n",
        "x = 10  # Valor inicial\n",
        "\n",
        "# Lista para almacenar los valores de x\n",
        "x_values = [x]\n",
        "\n",
        "# Proceso de gradiente descendiente\n",
        "for i in range(iterations):\n",
        "    gradient = df(x)\n",
        "    x = x - learning_rate * gradient\n",
        "    x_values.append(x)\n",
        "\n",
        "# Visualización\n",
        "plt.figure(figsize=(10, 6))\n",
        "x_range = np.linspace(-10, 10, 400)\n",
        "plt.plot(x_range, f(x_range), label='f(x) = x²')\n",
        "plt.scatter(x_values, [f(x) for x in x_values], color='red', label='Pasos del Gradiente Descendiente')\n",
        "for i, (x_val, y_val) in enumerate(zip(x_values, [f(x) for x in x_values])):\n",
        "    plt.text(x_val, y_val, f'Iter {i}', fontsize=8)\n",
        "plt.title('Gradiente Descendiente para f(x) = x²')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('f(x)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8HAZqvFHICDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Red Neuronal Convolucional (CNN) - Digit Recognizer"
      ],
      "metadata": {
        "id": "Hxl5uVNiHcZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Red Neuronal Convolucional (CNN):**  \n",
        "Diseñada para imágenes, usa capas convolucionales y pooling para extraer y reducir características.\n"
      ],
      "metadata": {
        "id": "wsuZkG1LHguO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Cargar y explorar el dataset"
      ],
      "metadata": {
        "id": "Y-oOxgy0HkIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "# Cargar el dataset MNIST\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Mostrar información básica\n",
        "print(\"Dimensiones del conjunto de entrenamiento:\", X_train_full.shape)\n",
        "print(\"Dimensiones del conjunto de prueba:\", X_test.shape)\n",
        "print(\"Ejemplo de etiquetas:\", y_train_full[:5])"
      ],
      "metadata": {
        "id": "uLfcmbB6Hd7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Preprocesamiento"
      ],
      "metadata": {
        "id": "KAy0FKkiHm8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Normalizar los valores de los píxeles al rango [0, 1]\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Añadir dimensión para el canal (1, porque son imágenes en escala de grises)\n",
        "X_train_full = X_train_full.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Dividir el conjunto de entrenamiento en entrenamiento y validación\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Dimensiones de X_train:\", X_train.shape)\n",
        "print(\"Dimensiones de X_val:\", X_val.shape)\n",
        "print(\"Dimensiones de X_test:\", X_test.shape)"
      ],
      "metadata": {
        "id": "9GUCsfKwHnpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Construcción del modelo CNN"
      ],
      "metadata": {
        "id": "PlNRBjkEI46H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_cnn = keras.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_cnn.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "model_cnn.summary()"
      ],
      "metadata": {
        "id": "GrKvoJYyI5vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Entrenamiento"
      ],
      "metadata": {
        "id": "wRn69kYmJEHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_cnn = model_cnn.fit(X_train, y_train,\n",
        "                            epochs=10,\n",
        "                            batch_size=64,\n",
        "                            validation_data=(X_val, y_val),\n",
        "                            verbose=1)"
      ],
      "metadata": {
        "id": "WLTmAs1cJEgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5 Evaluación y Visualización"
      ],
      "metadata": {
        "id": "Yuo1PfFnJOkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Predicciones en el conjunto de prueba\n",
        "y_pred = np.argmax(model_cnn.predict(X_test), axis=1)"
      ],
      "metadata": {
        "id": "H7W8XhEtJUx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Métricas\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "a0IlX6SZJa3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de Confusión\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Matriz de Confusión - CNN')\n",
        "plt.xlabel('Predicho')\n",
        "plt.ylabel('Real')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7VsQ5d55Jckc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pérdida y Precisión\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history_cnn.history['loss'], label='Pérdida Entrenamiento')\n",
        "plt.plot(history_cnn.history['val_loss'], label='Pérdida Validación')\n",
        "plt.title('Pérdida - CNN')\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history_cnn.history['accuracy'], label='Precisión Entrenamiento')\n",
        "plt.plot(history_cnn.history['val_accuracy'], label='Precisión Validación')\n",
        "plt.title('Precisión - CNN')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4AcKgaghJeNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplos de Predicciones\n",
        "fig, axes = plt.subplots(5, 5, figsize=(15,15))\n",
        "axes = axes.ravel()\n",
        "for i in range(25):\n",
        "    axes[i].imshow(X_test[i].reshape(28,28), cmap='gray')\n",
        "    axes[i].set_title(f\"Pred: {y_pred[i]}\\nReal: {y_test[i]}\")\n",
        "    axes[i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yfwYW5p8Jg8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Red Neuronal LSTM - Stock Prices"
      ],
      "metadata": {
        "id": "QZ68WJUlJuvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Red Neuronal de Memoria a Largo Plazo (LSTM):**\n",
        "\n",
        "Ideal para datos secuenciales, como series temporales de precios de acciones."
      ],
      "metadata": {
        "id": "pKrGAd6JJw90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Cargar y explorar el dataset"
      ],
      "metadata": {
        "id": "jBe5g1IjJ1s9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"borismarjanovic/price-volume-data-for-all-us-stocks-etfs\")\n",
        "stock_path = os.path.join(path, 'Stocks/aapl.us.txt')\n",
        "df_stock = pd.read_csv(stock_path)\n",
        "print(\"Primeras filas del dataset:\")\n",
        "print(df_stock.head())"
      ],
      "metadata": {
        "id": "8n4r1pChJ1AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Preprocesamiento"
      ],
      "metadata": {
        "id": "6tr6JVzoKgKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = df_stock['Close'].values.reshape(-1, 1)\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)"
      ],
      "metadata": {
        "id": "vxQfdWRAJvbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i+seq_length])\n",
        "        y.append(data[i+seq_length])\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "cYxCeHHPKjLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 60\n",
        "X, y = create_sequences(data_scaled, seq_length)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "2DhrRE4YKlGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Construcción del modelo LSTM"
      ],
      "metadata": {
        "id": "89nSZNE2KnSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = keras.Sequential([\n",
        "    layers.LSTM(50, return_sequences=True, input_shape=(seq_length, 1)),\n",
        "    layers.LSTM(50),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "model_lstm.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model_lstm.summary()"
      ],
      "metadata": {
        "id": "H735mULvKnsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 Entrenamiento"
      ],
      "metadata": {
        "id": "4wsCuocmKqYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_lstm = model_lstm.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)"
      ],
      "metadata": {
        "id": "9ATK_wfVKq4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5 Evaluación y Visualización"
      ],
      "metadata": {
        "id": "XTmCTz52Kt4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluación\n",
        "y_pred = model_lstm.predict(X_test)\n",
        "y_pred = scaler.inverse_transform(y_pred)\n",
        "y_test = scaler.inverse_transform(y_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100"
      ],
      "metadata": {
        "id": "uPAjG1F5KwpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"MAPE: {mape:.4f}%\")"
      ],
      "metadata": {
        "id": "H7sq6shBKr3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(MSE: 0.6853, RMSE: 0.8279, MAE: 0.4284, MAPE: 11.3580%) indican que el modelo LSTM tiene un rendimiento moderado para predecir precios de acciones. El error promedio absoluto es de 0.4284 unidades y el error porcentual es de 11.36%, lo cual sugiere que las predicciones son razonables pero no perfectas.\n",
        "\n"
      ],
      "metadata": {
        "id": "og5s7zn9RSTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplos de Predicciones para LSTM\n",
        "# Seleccionamos un subconjunto de 100 puntos para visualizar\n",
        "n_points = 100\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test[:n_points], label='Valores Reales', color='blue')\n",
        "plt.plot(y_pred[:n_points], label='Predicciones', color='red', linestyle='--')\n",
        "plt.title('Predicciones vs. Valores Reales - LSTM (Primeros 100 puntos)')\n",
        "plt.xlabel('Índice')\n",
        "plt.ylabel('Precio de Cierre (Normalizado)')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lXRVSDW1Ji8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de Dispersión\n",
        "# Muestra la relación entre valores reales y predichos en un gráfico de dispersión.\n",
        "# Los puntos cercanos a la línea roja (y=x) indican predicciones precisas.\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel('Valores Reales')\n",
        "plt.ylabel('Predicciones')\n",
        "plt.title('Predicciones vs. Valores Reales - LSTM')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "77cJCArYTEaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograma de Errores\n",
        "# Muestra la distribución de los errores (diferencia entre valores reales y predichos).\n",
        "# La curva KDE indica la densidad; un pico cerca de 0 sugiere predicciones precisas.\n",
        "errors = y_test - y_pred\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.histplot(errors, bins=50, kde=True)\n",
        "plt.title('Distribución de Errores - LSTM')\n",
        "plt.xlabel('Error')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqbIBoXmTFPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pérdida\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(history_lstm.history['loss'], label='Pérdida Entrenamiento')\n",
        "plt.plot(history_lstm.history['val_loss'], label='Pérdida Validación')\n",
        "plt.title('Pérdida - LSTM')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yDzXcK73Lce3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Residuos\n",
        "# Grafica los errores (residuos) frente al índice de las predicciones.\n",
        "# Puntos cerca de la línea roja (y=0) indican predicciones precisas.\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(errors, 'o', alpha=0.5)\n",
        "plt.axhline(0, color='r', linestyle='--')\n",
        "plt.title('Residuos - LSTM')\n",
        "plt.xlabel('Índice')\n",
        "plt.ylabel('Error')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C2hds3CzTIVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Conclusiones\n",
        "- ANN: Clasificación binaria con métricas detalladas y visualizaciones.\n",
        "- CNN: Clasificación multiclase con ejemplos y distribución de clases.\n",
        "- LSTM: Predicción de series temporales con análisis de errores extendido."
      ],
      "metadata": {
        "id": "E5zBPJdOLg_H"
      }
    }
  ]
}